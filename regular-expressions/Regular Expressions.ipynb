{
 "metadata": {
  "name": "",
  "signature": "sha256:3efe00ecd778d4d387ec4c3e2d2d38ce299a6ca0e174ba5d2a0e577d6b1f8288"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Regular Expressions playground\n",
      "\n",
      "I decided I wanted to write a regular expressions library. I don't know exactly why. It seemed cool, and I've never consciously worked with what I've heard as finite state automata. Here we go!\n",
      "\n",
      "\n",
      "# Initial thoughts\n",
      "\n",
      "Just a few stray thoughts spinning around:\n",
      "\n",
      " - Anchors seem real important for efficient matching\n",
      " - \"Compiling\" an expression will involve converting it into a more actionable representation/structure\n",
      "\n",
      "I'm gonna start simply by matching only a string."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import collections\n",
      "\n",
      "\n",
      "# Th[is]? i. (a) test{2,6}\\. (Or|is|it?)\n",
      "\n",
      "T_EOF = -1       # Fake token to mark end of input. Makes parsing a bit easier.\n",
      "T_STRING = 0     # abcdef\\[\n",
      "T_DOT = 1        # .\n",
      "T_QUESTION = 2   # ?\n",
      "T_ASTERISK = 3   # *\n",
      "T_LBRACE = 4     # {\n",
      "T_RBRACE = 5     # }\n",
      "T_LBRACKET = 6   # [\n",
      "T_RBRACKET = 7   # ]\n",
      "T_LPAREN = 8     # (\n",
      "T_RPAREN = 9     # )\n",
      "T_COMMA = 10     # ,\n",
      "T_PIPE = 11      # |\n",
      "\n",
      "# For error reporting purposes\n",
      "TOKEN_NAMES = {\n",
      "    T_STRING: 'STRING',\n",
      "    T_DOT: 'DOT',\n",
      "    T_QUESTION: 'QUESTION',\n",
      "    T_ASTERISK: 'ASTERISK',\n",
      "    T_LBRACE: 'LBRACE',\n",
      "    T_RBRACE: 'RBRACE',\n",
      "    T_LBRACKET: 'LBRACKET',\n",
      "    T_RBRACKET: 'RBRACKET',\n",
      "    T_LPAREN: 'LPAREN',\n",
      "    T_RPAREN: 'RPAREN',\n",
      "    T_COMMA: 'COMMA',\n",
      "    T_PIPE: 'PIPE',\n",
      "}\n",
      "\n",
      "\n",
      "def _tokenize(s):\n",
      "    SINGLES = {\n",
      "        '.': T_DOT,\n",
      "        '?': T_QUESTION,\n",
      "        '*': T_ASTERISK,\n",
      "        '{': T_LBRACE,\n",
      "        '}': T_RBRACE,\n",
      "        '[': T_LBRACKET,\n",
      "        ']': T_RBRACKET,\n",
      "        '(': T_LPAREN,\n",
      "        ')': T_RPAREN,\n",
      "        ',': T_COMMA,\n",
      "        '|': T_PIPE,\n",
      "    }\n",
      "\n",
      "    Token = collections.namedtuple('Token', ['type', 'text', 'index'])\n",
      "\n",
      "    tokens = []\n",
      "    _literal = []\n",
      "    _literal_start = None\n",
      "    i = 0\n",
      "\n",
      "    def emit(type, text=None, index=None):\n",
      "        if text is None:\n",
      "            text = c\n",
      "        if index is None:\n",
      "            index = i\n",
      "        tokens.append(Token(type, text, index))\n",
      "\n",
      "    def literal():\n",
      "        nonlocal _literal_start\n",
      "        if _literal_start is None:\n",
      "            _literal_start = i\n",
      "        _literal.append(c)\n",
      "\n",
      "    def close_literal():\n",
      "        nonlocal _literal, _literal_start\n",
      "        if _literal:\n",
      "            text = ''.join(_literal)\n",
      "            emit(T_STRING, text, _literal_start)\n",
      "            _literal = []\n",
      "            _literal_start = None\n",
      "\n",
      "    while i < len(s):\n",
      "        c = s[i]\n",
      "        if c in SINGLES:\n",
      "            close_literal()\n",
      "            emit(SINGLES[c])\n",
      "        elif c == '\\\\':\n",
      "            # TODO: figure out what to really do here\n",
      "            if s[i+1] in SINGLES:\n",
      "                i += 1\n",
      "                literal()\n",
      "            else:\n",
      "                raise NotImplemented\n",
      "        else:\n",
      "            literal()\n",
      "\n",
      "        i += 1\n",
      "    close_literal()\n",
      "\n",
      "    emit(T_EOF, '')\n",
      "    return tokens\n",
      "\n",
      "\n",
      "class Match(object):\n",
      "    def __init__(self, source, text, position, groups=()):\n",
      "        self.source = source\n",
      "        self.text = text\n",
      "        self.start = position\n",
      "        self.end = self.start + len(self.text)\n",
      "        self._groups = (text,) + tuple(groups)\n",
      "\n",
      "    def group(self, n):\n",
      "        return self._groups[n]\n",
      "\n",
      "    def groups(self):\n",
      "        return self._groups\n",
      "\n",
      "\n",
      "S_STRING = 0\n",
      "\n",
      "\n",
      "class Symbol(object):\n",
      "    def __init__(self, type_, text=None, children=None):\n",
      "        self.type = type_\n",
      "        self.text = text\n",
      "        if children is None:\n",
      "            children = ()\n",
      "        self.children = tuple(children)\n",
      "\n",
      "    def save(self, context, text):\n",
      "        \"\"\"Save the text matched for this symbol to the context\"\"\"\n",
      "        context[self] = text\n",
      "\n",
      "    def text(self, context):\n",
      "        if self in context:\n",
      "            return context[self]\n",
      "        elif self.children:\n",
      "            return ''.join(c.text(context) for c in self.children)\n",
      "\n",
      "\n",
      "class RegularExpression(object):\n",
      "    def __init__(self, source, symbols):\n",
      "        \"\"\"\n",
      "        :type source: str\n",
      "        :type symbols: list of Symbol\n",
      "        \"\"\"\n",
      "        self.source = source\n",
      "        self.symbols = symbols\n",
      "    \n",
      "    def __repr__(self):\n",
      "        return 'yre.compile(%r)' % self.source\n",
      "\n",
      "    def match(self, s):\n",
      "        context = {}\n",
      "        source = s\n",
      "        i = 0\n",
      "        t = 0\n",
      "        while i < len(s) and t < len(self.symbols):\n",
      "            symbol = self.symbols[t]\n",
      "            s = s[i:]\n",
      "            if symbol.type == S_STRING:\n",
      "                if s.startswith(symbol.text):\n",
      "                    symbol.save(context, symbol.text)\n",
      "                    i += len(symbol.text)\n",
      "                    t += 1\n",
      "                    continue\n",
      "\n",
      "            return None\n",
      "        else:\n",
      "            text = source[:i+1]\n",
      "            return Match(source, text, 0)\n",
      "\n",
      "\n",
      "_cache = {}\n",
      "def compile(s):\n",
      "    if s in _cache:\n",
      "        return _cache[s]\n",
      "    \n",
      "    tokens = _tokenize(s)\n",
      "    i = 0\n",
      "    pieces = []  # Intermediate storage for children\n",
      "    symbols = []\n",
      "    stack = []\n",
      "    expected_ends = []\n",
      "    \n",
      "    def emit(type, text=None, children=()):\n",
      "        nonlocal pieces\n",
      "        if children is None:\n",
      "            children = pieces\n",
      "            pieces = []\n",
      "        symbols.append(Symbol(type, text, children))\n",
      "    \n",
      "    def expect(*types, save=False):\n",
      "        nonlocal i\n",
      "        if token.type not in types:\n",
      "            type_names = ', '.join(TOKEN_NAMES[t] for t in types)\n",
      "            raise SyntaxError(\n",
      "                'Unexpected %r, expected one of: %r' % (token, type_names))\n",
      "        if save:\n",
      "            pieces.append(token)\n",
      "        i += 1\n",
      "        return True\n",
      "    \n",
      "    def accept(*types, save=False):\n",
      "        nonlocal i\n",
      "        if token.type in types:\n",
      "            if save:\n",
      "                pieces.append(token)\n",
      "            i += 1\n",
      "            return True\n",
      "        else:\n",
      "            return False\n",
      "\n",
      "    def push(expected_end):\n",
      "        nonlocal symbols\n",
      "        stack.append(symbols)\n",
      "        expected_ends.append(expected_end)\n",
      "        symbols = []\n",
      "\n",
      "    def expected_end():\n",
      "        if expected_ends:\n",
      "            return expected_ends[-1]\n",
      "    \n",
      "    while i < len(tokens):\n",
      "        token = tokens[i]\n",
      "        if accept(T_STRING):\n",
      "            emit(S_STRING, text=token.text)\n",
      "        elif accept(T_LPAREN):\n",
      "            push(T_RPAREN)\n",
      "        elif accept(expected_end()):\n",
      "\n",
      "        else:\n",
      "            if expected_ends:\n",
      "                msg = 'Unexpected %r, expected %s' % (\n",
      "                    token, TOKEN_NAMES[expected_end()])\n",
      "            else:\n",
      "                msg = 'Unexpected %r' % (token,)\n",
      "            raise SyntaxError(msg)\n",
      "    \n",
      "    expression = RegularExpression(s, symbols)\n",
      "    _cache[s] = expression\n",
      "    return expression\n",
      "\n",
      "\n",
      "def match(pattern, string):\n",
      "    return compile(pattern).match(string)\n",
      "\n",
      "\n",
      "def search(pattern, string):\n",
      "    return compile(pattern).search(string)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert match('test', 'test').groups() == ('test',)\n",
      "assert match('(test)', 'test').groups() == ('test', 'test')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "not all arguments converted during string formatting",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-16-36a2bc5c4b8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'(test)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-15-c176c42ccb0d>\u001b[0m in \u001b[0;36mmatch\u001b[1;34m(pattern, string)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-15-c176c42ccb0d>\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[0memit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS_STRING\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mSyntaxError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unexpected %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[0mexpression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRegularExpression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: not all arguments converted during string formatting"
       ]
      }
     ],
     "prompt_number": 16
    }
   ],
   "metadata": {}
  }
 ]
}